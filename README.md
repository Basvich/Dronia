# Dronia

This project was generated with [Angular CLI](https://github.com/angular/angular-cli) version 15.2.1.

## Estrategia general

Se usa apredizage reforzado, partiendo de estados continuos y queriendo obtener (en principio) posibles acciones (finitas), con una predicci贸n de recompensa para cada una de ellas, que permita escoger la acci贸n que m谩s recompensa d谩 para controlar el dron.

En un ciclo de entrenamiento, se realizan 2 partes diferenciadas:

* Ciclo de simulaci贸n, en el que en cada paso, con el estado del dron (altura, velocidad), se ejecuta la predicci贸n de la red, y se toma la acci贸n mas favorable. Con el estado nuevo obtenido, se calcula una recompensa, y se guarda en una memoria temporal (solo los n 煤ltimos), el estado del dron, que acci贸n se tom贸, junto con la recompensa obtenida.
* Ciclo de aprendizaje, en el que se parte de los datos almacenados, y se pasan a la red para su aprendizaje.

En el ciclo de aprendizaje, se tiene una cierta probabilidad peque帽a de tomar otro camino, diferente al de mayor recompensa, lo que permite que se puedan explorar otras v铆as.

En el ciclo de aprendizaje, se usa una variaci贸n de la ecuacion de  en la que la recompensa que se usa para el aprendizaje es la suma ponderada entre la recompensa del paso, y la maxima recompensa esperada de los futuros casos.

> Al acabar un ciclo de simulaci贸n, dependiendo si se acab贸 por tiempo, por salirse de limites o simplemente conseguir el objetivo, se otorga una recompensa adicional, la cual se reparte hac铆a atr谩s 

> 锔 Es importante remarcar, que solo se modifica la recompensa correspondiente a la acci贸n que se prob贸, las demas acciones siguen con el valor que ten铆an, lo que puede reforzar comportamientos no optimos.

## Ejemplos

### Entrenamiento simple en 1D

En este caso, lo que se busca es partiendo de un espacio continuo, con las variables posici贸n y velocidad, se quiere realizar un entrenamiento reforzado para que el dron se mantenga estable a cierta altura.
En la red, tenemos 2 entradas, y 5 posibles estados de salida, correspondientes a las posibles acciones a tomar: 5 posibles niveles de potencia.

Para controlar el dron, se obtiene el array de las 5 posibles acciones, y se toma la que tenga la recompensa mayor.

El objetivo de la red, es entonces acabar entrenando el campo recompensa de cada uno de los posibles estados.

#### Jurado para las recompensas

Para valorar la recompensa asignada a un estado, se cre贸 una clase llamada *TReward*. La forma actual para calcular la recompensa, es calcular una posici贸n proyectada, que consiste en la posici贸n actual, a la que se le a帽ade la velocidad. Con esta posici贸n proyectada, entonces se obtiene el valor recompensa de forma lineal y mayor cuanto m谩s cerca se encuentre de la altura objetivo.

#### Problemas encontrados

Es muy importante que los estados iniciales del dron, sean aleatorios tanto en posici贸n como en velocidad, para permitir ir rellenando adecuadamente las posibles recompensas esperadas para cada estado diferente.

La red converge bastante r谩pidamente hacia el estado que considera mejor, el cual es mantener una fuerza neutra en el dron. Esto se ve en que en los datos obtenidos por la red, se nota la recompensa para el estado neutro, con bastante mas valor que las dem谩s.

Una vez que el dron tiende a mantenerse dentro de los limites pero simplemente quieto, casi sin tendencia a acercase a la altura objetivo, al ir realizando m谩s entrenamientos, se nota como esperado que las recompensas de los dem谩s estados van creciendo tambi茅n, pero ese proceso es tremendamente largo hasta que el dron aprenda a moverse de esas posiciones de estabilidad hacia la posici贸n deseada.


# Readme por defecto
### Development server

Run `ng serve` for a dev server. Navigate to `http://localhost:4200/`. The application will automatically reload if you change any of the source files.

### Code scaffolding

Run `ng generate component component-name` to generate a new component. You can also use `ng generate directive|pipe|service|class|guard|interface|enum|module`.

### Build

Run `ng build` to build the project. The build artifacts will be stored in the `dist/` directory.

### Running unit tests

Run `ng test` to execute the unit tests via [Karma](https://karma-runner.github.io).

### Running end-to-end tests

Run `ng e2e` to execute the end-to-end tests via a platform of your choice. To use this command, you need to first add a package that implements end-to-end testing capabilities.

### Further help

To get more help on the Angular CLI use `ng help` or go check out the [Angular CLI Overview and Command Reference](https://angular.io/cli) page.
